#!/usr/bin/env python3
"""
My Daily Feed - æƒ…å ±ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ„ãƒ¼ãƒ«
å„ã‚½ãƒ¼ã‚¹ã‹ã‚‰æœ€æ–°æƒ…å ±ã‚’å–å¾—ã—ã€HTMLãƒšãƒ¼ã‚¸ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
è‹±èªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯è‡ªå‹•ã§æ—¥æœ¬èªã«ç¿»è¨³ã•ã‚Œã¾ã™ã€‚
"""

import feedparser
import requests
from bs4 import BeautifulSoup
from datetime import datetime, timezone, timedelta
from deep_translator import GoogleTranslator
import json
import html
import re
import time

JST = timezone(timedelta(hours=9))

# ===================== ã‚½ãƒ¼ã‚¹å®šç¾© =====================

SOURCES = {
    "ochiai_note": {
        "name": "è½åˆé™½ä¸€",
        "type": "rss",
        "url": "https://note.com/ochyai/rss",
        "emoji": "ğŸ§ ",
        "platform": "note",
    },
    "ochiai_yt": {
        "name": "è½åˆé™½ä¸€",
        "type": "youtube_search",
        "query": "è½åˆé™½ä¸€",
        "emoji": "ğŸ§ ",
        "platform": "YouTube",
        "max_age_days": 90,
    },
    "karpathy_yt": {
        "name": "Andrej Karpathy",
        "type": "rss",
        "url": "https://www.youtube.com/feeds/videos.xml?channel_id=UCXUPKJO5MZQN11PqgIvyuvQ",
        "emoji": "ğŸ¤–",
        "platform": "YouTube",
    },
    "hardfork": {
        "name": "Hard Fork",
        "type": "rss",
        "url": "https://feeds.simplecast.com/l2i9YnTd",
        "emoji": "ğŸ™ï¸",
        "platform": "Podcast",
    },
    "every": {
        "name": "Every",
        "type": "scrape",
        "url": "https://every.to",
        "emoji": "ğŸ“",
        "platform": "Newsletter",
    },
    "moltbook": {
        "name": "Moltbook",
        "type": "scrape",
        "url": "https://www.moltbook.com",
        "emoji": "ğŸ“š",
        "platform": "Community",
    },
    "amodei": {
        "name": "Dario Amodei",
        "type": "scrape",
        "url": "https://darioamodei.com",
        "emoji": "ğŸ›ï¸",
        "platform": "Blog",
    },
    "technium": {
        "name": "Kevin Kelly",
        "type": "rss",
        "url": "https://kk.org/thetechnium/feed/",
        "emoji": "ğŸ”®",
        "platform": "The Technium",
    },
    "tedchiang": {
        "name": "Ted Chiang",
        "type": "scrape",
        "url": "https://www.newyorker.com/contributors/ted-chiang",
        "emoji": "âœï¸",
        "platform": "The New Yorker",
    },
    "wired_jp": {
        "name": "WIRED JAPAN",
        "type": "rss",
        "url": "https://wired.jp/rssfeeder/",
        "emoji": "âš¡",
        "platform": "WIRED",
    },
}

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36"
}

# ===================== äºŒåå››ç¯€æ°—ãƒ»ä¸ƒåäºŒå€™ =====================

# 2026å¹´ã®äºŒåå››ç¯€æ°—ã¨ä¸ƒåäºŒå€™ï¼ˆæš¦ç”Ÿæ´»ãƒ»å›½ç«‹å¤©æ–‡å°ãƒ™ãƒ¼ã‚¹ï¼‰
SEKKI_72KOU = [
    # (é–‹å§‹æœˆæ—¥, çµ‚äº†æœˆæ—¥, ç¯€æ°—, å€™å, å€™èª­ã¿, ä¸€è¨€)
    ("01-05", "01-09", "å°å¯’", "èŠ¹ä¹ƒæ „", "ã›ã‚Šã™ãªã‚ã¡ã•ã‹ã†", "èŠ¹ãŒæ°´è¾ºã§åŠ›å¼·ãè‚²ã¡å§‹ã‚ã‚‹é ƒã€‚ä¸ƒè‰ãŒã‚†ã§æ–°å¹´ã®ä½“ã‚’æ•´ãˆã¾ã™"),
    ("01-10", "01-14", "å°å¯’", "æ°´æ³‰å‹•", "ã—ã¿ãšã‚ãŸãŸã‹ã‚’ãµãã‚€", "åœ°ä¸­ã§å‡ã£ãŸæ³‰ã®æ°´ãŒã‚ãšã‹ã«å‹•ãå‡ºã™é ƒã€‚æ˜¥ã®æ°—é…ãŒåœ°ã®åº•ã‹ã‚‰"),
    ("01-15", "01-19", "å°å¯’", "é›‰å§‹é›Š", "ãã˜ã¯ã˜ã‚ã¦ãªã", "é›„ã®é›‰ãŒé³´ãå§‹ã‚ã‚‹é ƒã€‚æ±‚æ„›ã®å£°ãŒå†¬ã®é‡ã«éŸ¿ãã¾ã™"),
    ("01-20", "01-24", "å¤§å¯’", "æ¬¾å†¬è¯", "ãµãã®ã¯ãªã•ã", "è•—ã®è–¹ãŒé›ªã®ä¸‹ã‹ã‚‰ãã£ã¨é¡”ã‚’å‡ºã™é ƒã€‚æ˜¥ä¸€ç•ªã®ä¾¿ã‚Šã§ã™"),
    ("01-25", "01-29", "å¤§å¯’", "æ°´æ²¢è…¹å …", "ã•ã‚ã¿ãšã“ãŠã‚Šã¤ã‚ã‚‹", "æ²¢ã®æ°´ãŒåšãå¼µã‚Šã¤ã‚ã¦å‡ã‚‹é ƒã€‚å¯’ã•ã®åº•ã§ã™ãŒã€å…‰ã¯æ—¥ã”ã¨ã«å¼·ã"),
    ("01-30", "02-03", "å¤§å¯’", "é¶å§‹ä¹³", "ã«ã‚ã¨ã‚Šã¯ã˜ã‚ã¦ã¨ã‚„ã«ã¤ã", "é¶ãŒåµã‚’ç”£ã¿å§‹ã‚ã‚‹é ƒã€‚æ˜¥ã«å‘ã‘ã¦ç”Ÿå‘½ãŒå‹•ãå‡ºã—ã¾ã™"),
    ("02-04", "02-08", "ç«‹æ˜¥", "æ±é¢¨è§£å‡", "ã¯ã‚‹ã‹ãœã“ãŠã‚Šã‚’ã¨ã", "æ˜¥é¢¨ãŒå¹ã„ã¦ã€å‡ã£ã¦ã„ãŸå·ã‚„åœ°é¢ã®æ°·ãŒå°‘ã—ãšã¤è§£ã‘å§‹ã‚ã‚‹é ƒ"),
    ("02-09", "02-13", "ç«‹æ˜¥", "é»„é¶¯çç†", "ã†ãã„ã™ãªã", "é¶¯ãŒå±±é‡Œã§ç¾ã—ã„å£°ã§ã•ãˆãšã‚Šå§‹ã‚ã‚‹é ƒã€‚æ˜¥ã®è¨ªã‚Œã‚’å‘Šã’ã‚‹å£°"),
    ("02-14", "02-18", "ç«‹æ˜¥", "é­šä¸Šæ°·", "ã†ãŠã“ãŠã‚Šã‚’ã„ãšã‚‹", "æ°·ãŒå‰²ã‚Œã¦ã€ãã®éš™é–“ã‹ã‚‰é­šãŒé£›ã³è·³ã­ã‚‹é ƒã€‚æ°´ã®ä¸­ã«ã‚‚æ˜¥ãŒæ¥ã¾ã™"),
    ("02-19", "02-23", "é›¨æ°´", "åœŸè„‰æ½¤èµ·", "ã¤ã¡ã®ã—ã‚‡ã†ã†ã‚‹ãŠã„ãŠã“ã‚‹", "é›ªãŒé›¨ã«å¤‰ã‚ã‚Šã€åœŸãŒæ½¤ã„å§‹ã‚ã‚‹é ƒã€‚å¤§åœ°ãŒç›®ã‚’è¦šã¾ã—ã¾ã™"),
    ("02-24", "02-28", "é›¨æ°´", "éœå§‹é†", "ã‹ã™ã¿ã¯ã˜ã‚ã¦ãŸãªã³ã", "æ˜¥éœãŒãŸãªã³ãå§‹ã‚ã‚‹é ƒã€‚é ãã®æ™¯è‰²ãŒã‚„ã‚ã‚‰ã‹ãã«ã˜ã¿ã¾ã™"),
    ("03-01", "03-05", "é›¨æ°´", "è‰æœ¨èŒå‹•", "ãã†ã‚‚ãã‚ã°ãˆã„ãšã‚‹", "è‰ã‚„æœ¨ã®èŠ½ãŒè†¨ã‚‰ã‚“ã§èŒãˆå§‹ã‚ã‚‹é ƒã€‚ã„ã‚ˆã„ã‚ˆæ˜¥æœ¬ç•ªãŒè¿‘ã¥ãã¾ã™"),
    ("03-06", "03-10", "å•“èŸ„", "èŸ„è™«å•“æˆ¸", "ã™ã”ã‚‚ã‚Šã‚€ã—ã¨ã‚’ã²ã‚‰ã", "å†¬ã”ã‚‚ã‚Šã®è™«ãŒåœŸã®ä¸­ã‹ã‚‰å‡ºã¦ãã‚‹é ƒã€‚å¤§åœ°ãŒç›®è¦šã‚ã¾ã™"),
    ("03-11", "03-15", "å•“èŸ„", "æ¡ƒå§‹ç¬‘", "ã‚‚ã‚‚ã¯ã˜ã‚ã¦ã•ã", "æ¡ƒã®èŠ±ãŒã»ã“ã‚ã³å§‹ã‚ã‚‹é ƒã€‚èŠ±ãŒå’²ãã“ã¨ã‚’ã€Œç¬‘ã†ã€ã¨è¡¨ã™ç¾ã—ã„è¡¨ç¾"),
    ("03-16", "03-20", "å•“èŸ„", "èœè™«åŒ–è¶", "ãªã‚€ã—ã¡ã‚‡ã†ã¨ãªã‚‹", "é’è™«ãŒã•ãªãã‹ã‚‰è¶ã¸ã¨ç”Ÿã¾ã‚Œå¤‰ã‚ã‚‹é ƒã€‚æ˜¥ã®å¤‰å®¹ã§ã™"),
    ("03-21", "03-25", "æ˜¥åˆ†", "é›€å§‹å·£", "ã™ãšã‚ã¯ã˜ã‚ã¦ã™ãã†", "é›€ãŒå·£ã‚’ä½œã‚Šå§‹ã‚ã‚‹é ƒã€‚æ˜¥ã®é™½æ°—ã«èª˜ã‚ã‚Œã¦"),
    ("03-26", "03-30", "æ˜¥åˆ†", "æ¡œå§‹é–‹", "ã•ãã‚‰ã¯ã˜ã‚ã¦ã²ã‚‰ã", "æ¡œã®èŠ±ãŒå’²ãå§‹ã‚ã‚‹é ƒã€‚æ—¥æœ¬ã®æ˜¥ã®è±¡å¾´ã§ã™"),
    ("03-31", "04-04", "æ˜¥åˆ†", "é›·ä¹ƒç™ºå£°", "ã‹ã¿ãªã‚Šã™ãªã‚ã¡ã“ãˆã‚’ã¯ã£ã™", "æ˜¥é›·ãŒé³´ã‚Šå§‹ã‚ã‚‹é ƒã€‚ç©ºæ°—ãŒå†¬ã‹ã‚‰æ˜¥ã¸ã¨å…¥ã‚Œæ›¿ã‚ã‚Šã¾ã™"),
    ("04-05", "04-09", "æ¸…æ˜", "ç„é³¥è‡³", "ã¤ã°ã‚ããŸã‚‹", "ç‡•ãŒå—ã®å›½ã‹ã‚‰æ¸¡ã£ã¦ãã‚‹é ƒã€‚æ˜¥ã®ä½¿è€…ã®åˆ°æ¥ã§ã™"),
    ("04-10", "04-14", "æ¸…æ˜", "é´»é›åŒ—", "ã“ã†ãŒã‚“ããŸã¸ã‹ãˆã‚‹", "é›ãŒåŒ—ã¸å¸°ã£ã¦ã„ãé ƒã€‚ç§‹ã«æ¥ãŸæ¸¡ã‚Šé³¥ã¨ã®åˆ¥ã‚Œã®å­£ç¯€"),
    ("04-15", "04-19", "æ¸…æ˜", "è™¹å§‹è¦‹", "ã«ã˜ã¯ã˜ã‚ã¦ã‚ã‚‰ã‚ã‚‹", "æ˜¥ã®é›¨ä¸ŠãŒã‚Šã«è™¹ãŒè¦‹ãˆå§‹ã‚ã‚‹é ƒã€‚ç©ºæ°—ãŒæ½¤ã¿ã¾ã™"),
    ("04-20", "04-24", "ç©€é›¨", "è‘­å§‹ç”Ÿ", "ã‚ã—ã¯ã˜ã‚ã¦ã—ã‚‡ã†ãš", "è‘¦ãŒèŠ½å¹ãå§‹ã‚ã‚‹é ƒã€‚æ°´è¾ºã«ç·‘ãŒæˆ»ã‚Šã¾ã™"),
    ("04-25", "04-29", "ç©€é›¨", "éœœæ­¢å‡ºè‹—", "ã—ã‚‚ã‚„ã‚“ã§ãªãˆã„ãšã‚‹", "éœœãŒé™ã‚Šãªããªã‚Šã€è‹—ãŒè‚²ã¤é ƒã€‚ç”°æ¤ãˆã®æº–å‚™ãŒå§‹ã¾ã‚Šã¾ã™"),
    ("04-30", "05-05", "ç©€é›¨", "ç‰¡ä¸¹è¯", "ã¼ãŸã‚“ã¯ãªã•ã", "ç‰¡ä¸¹ã®èŠ±ãŒå’²ãé ƒã€‚ç™¾èŠ±ã®ç‹ã¨å‘¼ã°ã‚Œã‚‹è¯ã‚„ã‹ã•"),
    ("05-06", "05-10", "ç«‹å¤", "è›™å§‹é³´", "ã‹ã‚ãšã¯ã˜ã‚ã¦ãªã", "è›™ãŒé³´ãå§‹ã‚ã‚‹é ƒã€‚ç”°ã‚“ã¼ã«å…ƒæ°—ãªåˆå”±ãŒéŸ¿ãã¾ã™"),
    ("05-11", "05-15", "ç«‹å¤", "èš¯èš“å‡º", "ã¿ã¿ãšã„ãšã‚‹", "ãƒŸãƒŸã‚ºãŒåœ°ä¸Šã«å‡ºã¦ãã‚‹é ƒã€‚å¤§åœ°ã®æµã¿ã‚’æ”¯ãˆã‚‹ç”Ÿãã‚‚ã®"),
    ("05-16", "05-20", "ç«‹å¤", "ç«¹ç¬‹ç”Ÿ", "ãŸã‘ã®ã“ã—ã‚‡ã†ãš", "ç­ãŒç”Ÿãˆã¦ãã‚‹é ƒã€‚ç«¹æ—ã«æ—¬ã®å‘³è¦šãŒå®Ÿã‚Šã¾ã™"),
    ("05-21", "05-25", "å°æº€", "èš•èµ·é£Ÿæ¡‘", "ã‹ã„ã“ãŠãã¦ãã‚ã‚’ã¯ã‚€", "èš•ãŒæ¡‘ã®è‘‰ã‚’ç››ã‚“ã«é£Ÿã¹å§‹ã‚ã‚‹é ƒ"),
    ("05-26", "05-30", "å°æº€", "ç´…èŠ±æ „", "ã¹ã«ã°ãªã•ã‹ã†", "ç´…èŠ±ãŒç››ã‚“ã«å’²ãé ƒã€‚é®®ã‚„ã‹ãªé»„è‰²ãŒé‡ã«åºƒãŒã‚Šã¾ã™"),
    ("05-31", "06-05", "å°æº€", "éº¦ç§‹è‡³", "ã‚€ãã®ã¨ãã„ãŸã‚‹", "éº¦ãŒç†Ÿã—ã¦åç©«ã‚’è¿ãˆã‚‹é ƒã€‚åˆå¤ã®é»„é‡‘è‰²"),
    ("06-06", "06-10", "èŠ’ç¨®", "è³è‚ç”Ÿ", "ã‹ã¾ãã‚Šã—ã‚‡ã†ãš", "ã‚«ãƒã‚­ãƒªãŒç”Ÿã¾ã‚Œã‚‹é ƒã€‚å°ã•ãªå‘½ã®å–¶ã¿ãŒå§‹ã¾ã‚Šã¾ã™"),
    ("06-11", "06-15", "èŠ’ç¨®", "è…è‰ç‚ºè›", "ãã•ã‚ŒãŸã‚‹ãã•ã»ãŸã‚‹ã¨ãªã‚‹", "è›ãŒé£›ã³å§‹ã‚ã‚‹é ƒã€‚å¤œã®æ°´è¾ºã«ã‚„ã•ã—ã„å…‰ãŒç¯ã‚Šã¾ã™"),
    ("06-16", "06-20", "èŠ’ç¨®", "æ¢…å­é»„", "ã†ã‚ã®ã¿ãã°ã‚€", "æ¢…ã®å®ŸãŒé»„è‰²ãè‰²ã¥ãé ƒã€‚æ¢…é›¨ã®èªæºã¨ã‚‚ã„ã‚ã‚Œã¾ã™"),
    ("06-21", "06-25", "å¤è‡³", "ä¹ƒæ±æ¯", "ãªã¤ã‹ã‚Œãã•ã‹ã‚‹ã‚‹", "å¤æ¯è‰ãŒæ¯ã‚Œå§‹ã‚ã‚‹é ƒã€‚å¤è‡³ã‚’éãã€é™½ã¯ã‚†ã£ãã‚Šã¨çŸ­ããªã‚Šã¾ã™"),
    ("06-26", "06-30", "å¤è‡³", "è–è’²è¯", "ã‚ã‚„ã‚ã¯ãªã•ã", "è–è’²ã®èŠ±ãŒå’²ãé ƒã€‚é›¨ã«æ¿¡ã‚ŒãŸç´«ãŒç¾ã—ã„"),
    ("07-01", "07-06", "å¤è‡³", "åŠå¤ç”Ÿ", "ã¯ã‚“ã’ã—ã‚‡ã†ãš", "åŠå¤ãŒç”Ÿãˆã‚‹é ƒã€‚ç”°æ¤ãˆã‚’çµ‚ãˆã‚‹ç›®å®‰ã¨ã•ã‚Œã¾ã™"),
    ("07-07", "07-11", "å°æš‘", "æ¸©é¢¨è‡³", "ã‚ã¤ã‹ãœã„ãŸã‚‹", "æ¸©ã‹ã„é¢¨ãŒå¹ãå§‹ã‚ã‚‹é ƒã€‚æœ¬æ ¼çš„ãªå¤ã®åˆ°æ¥ã§ã™"),
    ("07-12", "07-16", "å°æš‘", "è“®å§‹é–‹", "ã¯ã™ã¯ã˜ã‚ã¦ã²ã‚‰ã", "è“®ã®èŠ±ãŒé–‹ãå§‹ã‚ã‚‹é ƒã€‚æ—©æœã®æ± ã«æ¸…ã‚‰ã‹ãªç¾ã—ã•"),
    ("07-17", "07-22", "å°æš‘", "é·¹ä¹ƒå­¦ç¿’", "ãŸã‹ã™ãªã‚ã¡ã‚ã–ã‚’ãªã‚‰ã†", "é·¹ã®å¹¼é³¥ãŒé£›ã¶ã“ã¨ã‚’è¦šãˆã‚‹é ƒ"),
    ("07-23", "07-28", "å¤§æš‘", "æ¡å§‹çµèŠ±", "ãã‚Šã¯ã˜ã‚ã¦ã¯ãªã‚’ã‚€ã™ã¶", "æ¡ã®èŠ±ãŒå®Ÿã‚’çµã³å§‹ã‚ã‚‹é ƒ"),
    ("07-29", "08-02", "å¤§æš‘", "åœŸæ½¤æº½æš‘", "ã¤ã¡ã†ã‚‹ãŠã†ã¦ã‚€ã—ã‚ã¤ã—", "åœŸãŒæ¹¿ã‚Šè’¸ã—æš‘ããªã‚‹é ƒã€‚å¤ã®æš‘ã•ã®ç››ã‚Šã§ã™"),
    ("08-03", "08-07", "å¤§æš‘", "å¤§é›¨æ™‚è¡Œ", "ãŸã„ã†ã¨ãã©ãã«ãµã‚‹", "æ™‚æŠ˜å¤§é›¨ãŒé™ã‚‹é ƒã€‚å¤•ç«‹ãŒæš‘ã•ã‚’å’Œã‚‰ã’ã¾ã™"),
    ("08-08", "08-12", "ç«‹ç§‹", "æ¶¼é¢¨è‡³", "ã™ãšã‹ãœã„ãŸã‚‹", "æ¶¼ã—ã„é¢¨ãŒå¹ãå§‹ã‚ã‚‹é ƒã€‚æš¦ã®ä¸Šã§ã¯ç§‹ã®å§‹ã¾ã‚Š"),
    ("08-13", "08-17", "ç«‹ç§‹", "å¯’è‰é³´", "ã²ãã‚‰ã—ãªã", "ã²ãã‚‰ã—ãŒé³´ãå§‹ã‚ã‚‹é ƒã€‚å¤•æš®ã‚Œã«ã‚‚ã®æ‚²ã—ã„å£°ãŒéŸ¿ãã¾ã™"),
    ("08-18", "08-22", "ç«‹ç§‹", "è’™éœ§å‡é™", "ãµã‹ããã‚Šã¾ã¨ã†", "æ·±ã„éœ§ãŒç«‹ã¡ã“ã‚ã‚‹é ƒã€‚æœæ™©ã«ã©ã“ã‹ç§‹ã®æ°—é…"),
    ("08-23", "08-27", "å‡¦æš‘", "ç¶¿æŸé–‹", "ã‚ãŸã®ã¯ãªã—ã¹ã²ã‚‰ã", "ç¶¿ã®è¼ãŒé–‹ãé ƒã€‚ãµã‚ãµã‚ã®ç¶¿ãŒé¡”ã‚’å‡ºã—ã¾ã™"),
    ("08-28", "09-01", "å‡¦æš‘", "å¤©åœ°å§‹ç²›", "ã¦ã‚“ã¡ã¯ã˜ã‚ã¦ã•ã‚€ã—", "æš‘ã•ãŒã‚ˆã†ã‚„ãåã¾ã‚Šå§‹ã‚ã‚‹é ƒã€‚ç©ºãŒé«˜ããªã‚Šã¾ã™"),
    ("09-02", "09-07", "å‡¦æš‘", "ç¦¾ä¹ƒç™»", "ã“ãã‚‚ã®ã™ãªã‚ã¡ã¿ã®ã‚‹", "ç¨²ãŒå®Ÿã‚‹é ƒã€‚ç”°ã‚“ã¼ãŒé»„é‡‘è‰²ã«è‰²ã¥ãã¾ã™"),
    ("09-08", "09-12", "ç™½éœ²", "è‰éœ²ç™½", "ãã•ã®ã¤ã‚†ã—ã‚ã—", "è‰ã«é™ã‚ŠãŸéœ²ãŒç™½ãå…‰ã‚‹é ƒã€‚æœæ™©ã®å†·ãˆè¾¼ã¿ãŒå¢—ã—ã¾ã™"),
    ("09-13", "09-17", "ç™½éœ²", "é¶ºé´’é³´", "ã›ãã‚Œã„ãªã", "é¶ºé´’ãŒé³´ãå§‹ã‚ã‚‹é ƒã€‚ç§‹ã®æ°—é…ãŒè‰²æ¿ƒããªã‚Šã¾ã™"),
    ("09-18", "09-22", "ç™½éœ²", "ç„é³¥å»", "ã¤ã°ã‚ã•ã‚‹", "ç‡•ãŒå—ã¸å¸°ã£ã¦ã„ãé ƒã€‚æ˜¥ã«æ¥ãŸä½¿è€…ã¨ã®åˆ¥ã‚Œ"),
    ("09-23", "09-27", "ç§‹åˆ†", "é›·ä¹ƒåå£°", "ã‹ã¿ãªã‚Šã™ãªã‚ã¡ã“ãˆã‚’ãŠã•ã‚€", "é›·ãŒé³´ã‚‰ãªããªã‚‹é ƒã€‚ç©ºæ°—ãŒæ¾„ã¿å§‹ã‚ã¾ã™"),
    ("09-28", "10-02", "ç§‹åˆ†", "èŸ„è™«åæˆ¸", "ã‚€ã—ã‹ãã‚Œã¦ã¨ã‚’ãµã•ã", "è™«ãŒåœŸã®ä¸­ã«éš ã‚Œã¦æˆ¸ã‚’ãµã•ãé ƒã€‚å†¬æ”¯åº¦ã®å§‹ã¾ã‚Š"),
    ("10-03", "10-07", "ç§‹åˆ†", "æ°´å§‹æ¶¸", "ã¿ãšã¯ã˜ã‚ã¦ã‹ã‚‹ã‚‹", "ç”°ã®æ°´ã‚’æŠœã„ã¦ç¨²åˆˆã‚Šã®æº–å‚™ã‚’ã™ã‚‹é ƒ"),
    ("10-08", "10-12", "å¯’éœ²", "é´»é›æ¥", "ã“ã†ãŒã‚“ããŸã‚‹", "é›ãŒåŒ—ã‹ã‚‰æ¸¡ã£ã¦ãã‚‹é ƒã€‚ç§‹ã®ç©ºã«é›è¡Œã®åˆ—"),
    ("10-13", "10-17", "å¯’éœ²", "èŠèŠ±é–‹", "ããã®ã¯ãªã²ã‚‰ã", "èŠã®èŠ±ãŒå’²ãå§‹ã‚ã‚‹é ƒã€‚ç§‹ã®å½©ã‚Šã§ã™"),
    ("10-18", "10-22", "å¯’éœ²", "èŸ‹èŸ€åœ¨æˆ¸", "ãã‚Šãã‚Šã™ã¨ã«ã‚ã‚Š", "èŸ‹èŸ€ãŒæˆ¸å£ã§é³´ãé ƒã€‚ç§‹ã®å¤œé•·ã«è™«ã®éŸ³ãŒéŸ¿ãã¾ã™"),
    ("10-23", "10-27", "éœœé™", "éœœå§‹é™", "ã—ã‚‚ã¯ã˜ã‚ã¦ãµã‚‹", "éœœãŒåˆã‚ã¦é™ã‚Šã‚‹é ƒã€‚å†¬ã®è¶³éŸ³ãŒè¿‘ã¥ãã¾ã™"),
    ("10-28", "11-01", "éœœé™", "éœæ™‚æ–½", "ã“ã•ã‚ã¨ãã©ããµã‚‹", "å°é›¨ãŒã—ã¨ã—ã¨ã¨é™ã‚‹é ƒã€‚æ™©ç§‹ã®é™ã‹ãªé›¨"),
    ("11-02", "11-06", "éœœé™", "æ¥“è”¦é»„", "ã‚‚ã¿ã˜ã¤ãŸãã°ã‚€", "ç´…è‘‰ã‚„è”¦ãŒè‰²ã¥ãé ƒã€‚å±±ãŒç‡ƒãˆã‚‹ã‚ˆã†ãªç¾ã—ã•ã«"),
    ("11-07", "11-11", "ç«‹å†¬", "å±±èŒ¶å§‹é–‹", "ã¤ã°ãã¯ã˜ã‚ã¦ã²ã‚‰ã", "å±±èŒ¶èŠ±ãŒå’²ãå§‹ã‚ã‚‹é ƒã€‚å†¬ã®åº­ã«å½©ã‚Šã‚’æ·»ãˆã¾ã™"),
    ("11-12", "11-16", "ç«‹å†¬", "åœ°å§‹å‡", "ã¡ã¯ã˜ã‚ã¦ã“ãŠã‚‹", "å¤§åœ°ãŒå‡ã‚Šå§‹ã‚ã‚‹é ƒã€‚å†¬ãŒæœ¬æ ¼çš„ã«ã‚„ã£ã¦ãã¾ã™"),
    ("11-17", "11-21", "ç«‹å†¬", "é‡‘ç›é¦™", "ãã‚“ã›ã‚“ã‹ã•ã", "æ°´ä»™ã®èŠ±ãŒå’²ãå§‹ã‚ã‚‹é ƒã€‚æ¸…æ¥šãªé¦™ã‚ŠãŒæ¼‚ã„ã¾ã™"),
    ("11-22", "11-26", "å°é›ª", "è™¹è”µä¸è¦‹", "ã«ã˜ã‹ãã‚Œã¦ã¿ãˆãš", "è™¹ã‚’è¦‹ã‹ã‘ãªããªã‚‹é ƒã€‚å†¬ã®ç©ºæ°—ã¯ä¹¾ã„ã¦æ¾„ã‚“ã§ã„ã¾ã™"),
    ("11-27", "12-01", "å°é›ª", "æœ”é¢¨æ‰•è‘‰", "ããŸã‹ãœã“ã®ã¯ã‚’ã¯ã‚‰ã†", "åŒ—é¢¨ãŒæœ¨ã®è‘‰ã‚’å¹ãæ‰•ã†é ƒã€‚å†¬æ¯ã‚Œã®æ™¯è‰²"),
    ("12-02", "12-06", "å°é›ª", "æ©˜å§‹é»„", "ãŸã¡ã°ãªã¯ã˜ã‚ã¦ãã°ã‚€", "æ©˜ã®å®ŸãŒé»„è‰²ãè‰²ã¥ãå§‹ã‚ã‚‹é ƒ"),
    ("12-07", "12-11", "å¤§é›ª", "é–‰å¡æˆå†¬", "ãã‚‰ã•ã‚€ããµã‚†ã¨ãªã‚‹", "ç©ºãŒé‡ãé–‰ã–ã•ã‚Œã€æœ¬æ ¼çš„ãªå†¬ãŒè¨ªã‚Œã‚‹é ƒ"),
    ("12-12", "12-16", "å¤§é›ª", "ç†ŠèŸ„ç©´", "ãã¾ã‚ãªã«ã“ã‚‚ã‚‹", "ç†ŠãŒå†¬çœ ã®ãŸã‚ã«ç©´ã«å…¥ã‚‹é ƒã€‚å±±ã‚‚é™ã‹ã«çœ ã‚Šã«ã¤ãã¾ã™"),
    ("12-17", "12-21", "å¤§é›ª", "é±–é­šç¾¤", "ã•ã‘ã®ã†ãŠã‚€ã‚‰ãŒã‚‹", "é®­ãŒç¾¤ãŒã£ã¦å·ã‚’ä¸Šã‚‹é ƒã€‚å‘½ã‚’ã¤ãªãå£®å¤§ãªæ—…"),
    ("12-22", "12-26", "å†¬è‡³", "ä¹ƒæ±ç”Ÿ", "ãªã¤ã‹ã‚Œãã•ã—ã‚‡ã†ãš", "å¤æ¯è‰ãŒèŠ½ã‚’å‡ºã™é ƒã€‚å†¬è‡³ã‚’éãã€é™½ãŒå°‘ã—ãšã¤é•·ããªã‚Šã¾ã™"),
    ("12-27", "12-31", "å†¬è‡³", "éº‹è§’è§£", "ã•ã‚ã—ã‹ã®ã¤ã®ãŠã¤ã‚‹", "é¹¿ã®è§’ãŒè½ã¡ã‚‹é ƒã€‚æ–°ã—ã„å¹´ã¸ã®æº–å‚™ãŒå§‹ã¾ã‚Šã¾ã™"),
    ("01-01", "01-04", "å†¬è‡³", "é›ªä¸‹å‡ºéº¦", "ã‚†ãã‚ãŸã‚Šã¦ã‚€ãã®ã³ã‚‹", "é›ªã®ä¸‹ã§éº¦ãŒèŠ½ã‚’å‡ºã™é ƒã€‚è¦‹ãˆãªã„ã¨ã“ã‚ã§æ˜¥ã¸ã®æº–å‚™"),
]


def get_seasonal_message():
    """ä»Šæ—¥ã®æ—¥ä»˜ã«å¯¾å¿œã™ã‚‹ä¸ƒåäºŒå€™ã®æƒ…å ±ã‚’è¿”ã™"""
    now = datetime.now(JST)
    month_day = now.strftime("%m-%d")

    for start, end, sekki, kou_name, kou_reading, description in SEKKI_72KOU:
        # å¹´ã‚’ã¾ãŸãã‚±ãƒ¼ã‚¹ï¼ˆ12æœˆâ†’1æœˆï¼‰ã«å¯¾å¿œ
        if start <= end:
            if start <= month_day <= end:
                return sekki, kou_name, kou_reading, description
        else:
            if month_day >= start or month_day <= end:
                return sekki, kou_name, kou_reading, description

    return "ç«‹æ˜¥", "æ±é¢¨è§£å‡", "ã¯ã‚‹ã‹ãœã“ãŠã‚Šã‚’ã¨ã", "æ˜¥é¢¨ãŒå¹ã„ã¦æ°·ãŒè§£ã‘å§‹ã‚ã‚‹é ƒ"


# ===================== ç¿»è¨³ =====================

translator = GoogleTranslator(source="en", target="ja")


def is_english(text):
    """ãƒ†ã‚­ã‚¹ãƒˆãŒè‹±èªã‹ã©ã†ã‹ã‚’ç°¡æ˜“åˆ¤å®š"""
    if not text:
        return False
    ascii_chars = sum(1 for c in text if ord(c) < 128)
    return ascii_chars / max(len(text), 1) > 0.8


def translate_to_japanese(text):
    """è‹±èªãƒ†ã‚­ã‚¹ãƒˆã‚’æ—¥æœ¬èªã«ç¿»è¨³ï¼ˆç„¡æ–™ã®Google Translateä½¿ç”¨ï¼‰"""
    if not text or not is_english(text):
        return text
    try:
        if len(text) > 4500:
            text = text[:4500]
        result = translator.translate(text)
        return result if result else text
    except Exception as e:
        print(f"    âš ï¸ ç¿»è¨³ã‚¹ã‚­ãƒƒãƒ—: {str(e)[:50]}")
        return text


# ===================== ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ =====================

def time_ago(dt):
    """æ—¥æ™‚ã‚’ã€Œâ—¯æ™‚é–“å‰ã€ã€Œâ—¯æ—¥å‰ã€ãªã©ã«å¤‰æ›"""
    if dt is None:
        return ""
    now = datetime.now(timezone.utc)
    if dt.tzinfo is None:
        dt = dt.replace(tzinfo=timezone.utc)
    diff = now - dt
    hours = diff.total_seconds() / 3600
    if hours < 1:
        return "ãŸã£ãŸä»Š"
    elif hours < 24:
        return f"{int(hours)}æ™‚é–“å‰"
    elif hours < 48:
        return "1æ—¥å‰"
    elif hours < 168:
        return f"{int(hours / 24)}æ—¥å‰"
    else:
        weeks = int(hours / 168)
        if weeks <= 4:
            return f"{weeks}é€±é–“å‰"
        else:
            months = int(hours / 720)
            return f"{months}ãƒ¶æœˆå‰"


def clean_html(text):
    """HTMLã‚¿ã‚°ã‚’é™¤å»ã—ã¦ãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«"""
    if not text:
        return ""
    soup = BeautifulSoup(text, "html.parser")
    return soup.get_text(separator=" ", strip=True)[:300]


def parse_date(entry):
    """feedparserã®entryã‹ã‚‰æ—¥æ™‚ã‚’å–å¾—"""
    for field in ["published_parsed", "updated_parsed"]:
        t = entry.get(field)
        if t:
            try:
                return datetime(*t[:6], tzinfo=timezone.utc)
            except:
                pass
    return None


def parse_youtube_time(time_text):
    """YouTubeã®ã€Œ3æ™‚é–“å‰ã€ã€Œ2é€±é–“å‰ã€ãªã©ã®ç›¸å¯¾æ™‚é–“ã‚’è§£æ"""
    now = datetime.now(timezone.utc)
    if not time_text:
        return None
    num_match = re.search(r'(\d+)', time_text)
    if not num_match:
        return None
    num = int(num_match.group(1))
    if 'æ™‚é–“' in time_text or 'hour' in time_text:
        return now - timedelta(hours=num)
    elif 'æ—¥' in time_text or 'day' in time_text:
        return now - timedelta(days=num)
    elif 'é€±' in time_text or 'week' in time_text:
        return now - timedelta(weeks=num)
    elif 'ã‹æœˆ' in time_text or 'month' in time_text:
        return now - timedelta(days=num * 30)
    elif 'å¹´' in time_text or 'year' in time_text:
        return now - timedelta(days=num * 365)
    return None


def extract_image_from_entry(entry):
    """RSSã‚¨ãƒ³ãƒˆãƒªã‹ã‚‰ã‚µãƒ ãƒã‚¤ãƒ«ç”»åƒURLã‚’å–å¾—"""
    # media:thumbnail
    media_thumb = entry.get("media_thumbnail")
    if media_thumb and isinstance(media_thumb, list) and len(media_thumb) > 0:
        url = media_thumb[0].get("url", "")
        if url:
            return url

    # media:content
    media_content = entry.get("media_content")
    if media_content and isinstance(media_content, list):
        for mc in media_content:
            if mc.get("medium") == "image" or (mc.get("type", "").startswith("image")):
                return mc.get("url", "")

    # enclosure (podcasts often use this)
    enclosures = entry.get("enclosures", [])
    for enc in enclosures:
        if enc.get("type", "").startswith("image"):
            return enc.get("href", enc.get("url", ""))

    # image in feed content / summary
    summary = entry.get("summary", "") or entry.get("content", [{}])[0].get("value", "") if entry.get("content") else ""
    if summary:
        soup = BeautifulSoup(summary, "html.parser")
        img = soup.find("img", src=True)
        if img:
            return img["src"]

    return ""


# ===================== ãƒ‡ãƒ¼ã‚¿å–å¾— =====================

def fetch_rss(source_key, source):
    """RSSãƒ•ã‚£ãƒ¼ãƒ‰ã‹ã‚‰ã‚¢ã‚¤ãƒ†ãƒ ã‚’å–å¾—"""
    items = []
    max_age = source.get("max_age_days")
    try:
        print(f"  ğŸ“¡ RSSå–å¾—ä¸­: {source['name']} ({source['platform']})...")
        feed = feedparser.parse(source["url"])
        for entry in feed.entries[:10]:
            title = entry.get("title", "ï¼ˆã‚¿ã‚¤ãƒˆãƒ«ãªã—ï¼‰")
            link = entry.get("link", "")
            summary = clean_html(entry.get("summary", entry.get("description", "")))
            pub_date = parse_date(entry)
            image = extract_image_from_entry(entry)

            # YouTubeå‹•ç”»ã®å ´åˆã€ã‚µãƒ ãƒã‚¤ãƒ«ã‚’ç”Ÿæˆ
            if not image and "youtube.com" in link:
                vid_match = re.search(r'v=([^&]+)', link)
                if vid_match:
                    image = f"https://i.ytimg.com/vi/{vid_match.group(1)}/mqdefault.jpg"

            if max_age and pub_date:
                age_days = (datetime.now(timezone.utc) - pub_date).days
                if age_days > max_age:
                    continue

            if len(items) >= 5:
                break

            items.append({
                "source_key": source_key,
                "title": title,
                "summary": summary,
                "link": link,
                "date": pub_date,
                "time_ago": time_ago(pub_date),
                "image": image,
                "original_lang": "en" if is_english(title) else "ja",
            })
        print(f"  âœ… {len(items)}ä»¶å–å¾—")
    except Exception as e:
        print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {e}")
    return items


def search_youtube(source_key, source):
    """YouTubeæ¤œç´¢ã§å‹•ç”»ã‚’å–å¾—"""
    items = []
    query = source.get("query", "")
    max_age = source.get("max_age_days", 90)
    try:
        print(f"  ğŸ” YouTubeæ¤œç´¢ä¸­: {query}...")
        encoded_query = requests.utils.quote(query)
        url = f"https://www.youtube.com/results?search_query={encoded_query}&sp=CAI%3D"
        resp = requests.get(url, headers=HEADERS, timeout=15)

        match = re.search(r'ytInitialData\s*=\s*({.*?});</script>', resp.text, re.DOTALL)
        if not match:
            print("  âš ï¸ YouTubeæ¤œç´¢ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
            return items

        data = json.loads(match.group(1))

        try:
            contents = data['contents']['twoColumnSearchResultsRenderer']['primaryContents']['sectionListRenderer']['contents']
            for section in contents:
                video_items = section.get('itemSectionRenderer', {}).get('contents', [])
                for vi in video_items:
                    vr = vi.get('videoRenderer')
                    if not vr:
                        continue
                    vid = vr.get('videoId', '')
                    title = vr.get('title', {}).get('runs', [{}])[0].get('text', '')
                    channel = vr.get('ownerText', {}).get('runs', [{}])[0].get('text', '')
                    published = vr.get('publishedTimeText', {}).get('simpleText', '')
                    # ã‚µãƒ ãƒã‚¤ãƒ«å–å¾—
                    thumbs = vr.get('thumbnail', {}).get('thumbnails', [])
                    thumb_url = thumbs[-1].get('url', '') if thumbs else ''
                    if not thumb_url and vid:
                        thumb_url = f"https://i.ytimg.com/vi/{vid}/mqdefault.jpg"

                    if not title or not vid:
                        continue
                    pub_date = parse_youtube_time(published)
                    if pub_date and max_age:
                        age_days = (datetime.now(timezone.utc) - pub_date).days
                        if age_days > max_age:
                            continue

                    items.append({
                        "source_key": source_key,
                        "title": title,
                        "summary": f"ğŸ“º {channel}" if channel else "",
                        "link": f"https://www.youtube.com/watch?v={vid}",
                        "date": pub_date,
                        "time_ago": time_ago(pub_date) if pub_date else published,
                        "image": thumb_url,
                        "original_lang": "ja",
                    })
                    if len(items) >= 5:
                        break
                if len(items) >= 5:
                    break
        except (KeyError, IndexError) as e:
            print(f"  âš ï¸ YouTubeæ¤œç´¢ã®ãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—: {e}")

        print(f"  âœ… {len(items)}ä»¶å–å¾—")
    except Exception as e:
        print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {e}")
    return items


def scrape_every():
    """Every.toã®ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ã‹ã‚‰è¨˜äº‹ã‚’å–å¾—"""
    items = []
    seen_titles = set()
    skip_words = ["subscribe", "sign up", "log in", "newsletter", "cookie",
                  "introducing every", "pricing", "about", "advertise",
                  "view all", "read more", "careers", "contact"]
    try:
        print(f"  ğŸŒ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ä¸­: Every...")
        resp = requests.get("https://every.to", headers=HEADERS, timeout=15)
        soup = BeautifulSoup(resp.text, "html.parser")

        candidates = []
        for heading in soup.find_all(["h1", "h2", "h3"]):
            a_tag = heading.find("a", href=True)
            if a_tag:
                candidates.append(a_tag)

        for a_tag in soup.find_all("a", href=True):
            href = a_tag["href"]
            if re.match(r"^/[a-z-]+/[a-z0-9-]+", href) and len(href) > 15:
                candidates.append(a_tag)

        for a_tag in candidates:
            href = a_tag.get("href", "")
            if not href or href.startswith("#"):
                continue
            title_text = ""
            for child in a_tag.descendants:
                if isinstance(child, str):
                    title_text += child
            title_text = title_text.strip()
            title_text = re.sub(r'(?<=[A-Z])\s+(?=[a-z])', '', title_text)
            title_text = re.sub(r'\s+', ' ', title_text).strip()

            if not title_text or len(title_text) < 10 or len(title_text) > 200:
                continue
            if any(sw in title_text.lower() for sw in skip_words):
                continue
            title_lower = title_text.lower()
            if title_lower in seen_titles:
                continue
            seen_titles.add(title_lower)

            # è¿‘ãã®ç”»åƒã‚’æ¢ã™
            image = ""
            parent = a_tag.parent
            for _ in range(5):
                if parent is None:
                    break
                img = parent.find("img", src=True)
                if img and not img["src"].startswith("data:"):
                    image = img["src"]
                    break
                parent = parent.parent

            full_url = href if href.startswith("http") else f"https://every.to{href}"
            items.append({
                "source_key": "every",
                "title": title_text,
                "summary": "",
                "link": full_url,
                "date": None,
                "time_ago": "æœ€è¿‘",
                "image": image,
                "original_lang": "en",
            })
            if len(items) >= 5:
                break
        print(f"  âœ… {len(items)}ä»¶å–å¾—")
    except Exception as e:
        print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {e}")
    return items


def scrape_moltbook():
    """Moltbookã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—"""
    items = []
    try:
        print(f"  ğŸŒ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ä¸­: Moltbook...")
        requests.get("https://www.moltbook.com", headers=HEADERS, timeout=15)
        items.append({
            "source_key": "moltbook",
            "title": "Moltbook â€” AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆãƒ™ãƒ¼ã‚¿ç‰ˆï¼‰",
            "summary": "AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåŒå£«ãŒäº¤æµã™ã‚‹æ–°ã—ã„ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã€‚ãƒ™ãƒ¼ã‚¿ç‰ˆã®ãŸã‚æŠ•ç¨¿ã¯ã¾ã å°‘ãªã‚ã§ã™ã€‚",
            "link": "https://www.moltbook.com",
            "date": None,
            "time_ago": "",
            "image": "",
            "original_lang": "ja",
        })
        print(f"  âœ… {len(items)}ä»¶å–å¾—")
    except Exception as e:
        print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {e}")
    return items


def scrape_amodei():
    """Dario Amodeiã®å€‹äººãƒ–ãƒ­ã‚°ã‹ã‚‰è¨˜äº‹ã‚’å–å¾—"""
    items = []
    try:
        print(f"  ğŸŒ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ä¸­: Dario Amodei...")
        resp = requests.get("https://darioamodei.com", headers=HEADERS, timeout=15)
        soup = BeautifulSoup(resp.text, "html.parser")

        # ãƒ–ãƒ­ã‚°ã®ãƒªãƒ³ã‚¯ã‚’æ¢ã™
        for a_tag in soup.find_all("a", href=True):
            href = a_tag["href"]
            title_text = a_tag.get_text(strip=True)

            if not title_text or len(title_text) < 10 or len(title_text) > 300:
                continue

            skip = ["home", "about", "contact", "subscribe", "menu", "navigation",
                    "dario amodei", "privacy", "terms"]
            if any(sw in title_text.lower() for sw in skip):
                continue

            full_url = href if href.startswith("http") else f"https://darioamodei.com{href}"

            # ç”»åƒã‚’æ¢ã™
            image = ""
            parent = a_tag.parent
            for _ in range(4):
                if parent is None:
                    break
                img = parent.find("img", src=True)
                if img and not img["src"].startswith("data:"):
                    img_src = img["src"]
                    if not img_src.startswith("http"):
                        img_src = f"https://darioamodei.com{img_src}"
                    image = img_src
                    break
                parent = parent.parent

            items.append({
                "source_key": "amodei",
                "title": title_text,
                "summary": "",
                "link": full_url,
                "date": None,
                "time_ago": "",
                "image": image,
                "original_lang": "en",
            })
            if len(items) >= 5:
                break

        print(f"  âœ… {len(items)}ä»¶å–å¾—")
    except Exception as e:
        print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {e}")
    return items


def scrape_tedchiang():
    """Ted Chiangã®New Yorkerè¨˜äº‹ã‚’å–å¾—"""
    items = []
    try:
        print(f"  ğŸŒ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ä¸­: Ted Chiang (The New Yorker)...")
        resp = requests.get("https://www.newyorker.com/contributors/ted-chiang",
                          headers=HEADERS, timeout=15)
        soup = BeautifulSoup(resp.text, "html.parser")

        for a_tag in soup.find_all("a", href=True):
            href = a_tag["href"]
            # è¨˜äº‹ãƒªãƒ³ã‚¯ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
            if not re.search(r'/(magazine|culture|tech|news|science)/', href):
                continue

            title_text = a_tag.get_text(strip=True)
            if not title_text or len(title_text) < 10 or len(title_text) > 300:
                continue

            skip = ["subscribe", "sign in", "newsletter", "new yorker", "podcast",
                    "cartoon", "crossword", "goings on"]
            if any(sw in title_text.lower() for sw in skip):
                continue

            full_url = href if href.startswith("http") else f"https://www.newyorker.com{href}"

            # ç”»åƒ
            image = ""
            parent = a_tag.parent
            for _ in range(5):
                if parent is None:
                    break
                img = parent.find("img", src=True)
                if img and not img["src"].startswith("data:"):
                    image = img["src"]
                    break
                parent = parent.parent

            items.append({
                "source_key": "tedchiang",
                "title": title_text,
                "summary": "",
                "link": full_url,
                "date": None,
                "time_ago": "",
                "image": image,
                "original_lang": "en",
            })
            if len(items) >= 5:
                break

        print(f"  âœ… {len(items)}ä»¶å–å¾—")
    except Exception as e:
        print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {e}")
    return items


# ===================== ç¿»è¨³å‡¦ç† =====================

def translate_items(all_items):
    """è‹±èªã‚¢ã‚¤ãƒ†ãƒ ã®ã‚¿ã‚¤ãƒˆãƒ«ã¨ã‚µãƒãƒªãƒ¼ã‚’æ—¥æœ¬èªã«ç¿»è¨³"""
    en_items = [i for i in all_items if i.get("original_lang") == "en"]
    if not en_items:
        return

    print(f"\nğŸŒ è‹±èªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ {len(en_items)}ä»¶ã‚’æ—¥æœ¬èªã«ç¿»è¨³ä¸­...")

    for i, item in enumerate(en_items):
        original_title = item["title"]
        translated_title = translate_to_japanese(original_title)
        if translated_title != original_title:
            item["title_ja"] = translated_title
            item["title_en"] = original_title
            print(f"  âœ… {i+1}/{len(en_items)}: {original_title[:40]}...")
        else:
            item["title_ja"] = None
            item["title_en"] = original_title

        if item["summary"] and is_english(item["summary"]):
            item["summary_ja"] = translate_to_japanese(item["summary"])
        else:
            item["summary_ja"] = item["summary"]

        time.sleep(0.3)

    print(f"  âœ… ç¿»è¨³å®Œäº†")


# ===================== HTMLç”Ÿæˆ =====================

SOURCE_COLORS = {
    "ochiai_note": {"text": "#8B5E3C", "bg": "#FFF5ED", "badge_bg": "#F5E0CE"},
    "ochiai_yt":   {"text": "#8B5E3C", "bg": "#FFF5ED", "badge_bg": "#F5E0CE"},
    "karpathy_yt": {"text": "#3D7A3D", "bg": "#EFF8EF", "badge_bg": "#D4EDDA"},
    "hardfork":    {"text": "#B83B46", "bg": "#FFF0F1", "badge_bg": "#FADCE0"},
    "every":       {"text": "#2E6B96", "bg": "#EDF5FB", "badge_bg": "#D0E5F5"},
    "moltbook":    {"text": "#6B4E8B", "bg": "#F5F0FA", "badge_bg": "#E4D9F2"},
    "amodei":      {"text": "#2D6A4F", "bg": "#EDF7F0", "badge_bg": "#C8E6C9"},
    "technium":    {"text": "#5C6BC0", "bg": "#EDE7F6", "badge_bg": "#D1C4E9"},
    "tedchiang":   {"text": "#6D4C41", "bg": "#EFEBE9", "badge_bg": "#D7CCC8"},
    "wired_jp":    {"text": "#00695C", "bg": "#E0F2F1", "badge_bg": "#B2DFDB"},
}

def generate_html(all_items, output_path):
    """å…¨ã‚¢ã‚¤ãƒ†ãƒ ã‹ã‚‰HTMLãƒšãƒ¼ã‚¸ã‚’ç”Ÿæˆ"""
    all_items.sort(key=lambda x: x["date"] or datetime.min.replace(tzinfo=timezone.utc), reverse=True)

    now_jst = datetime.now(JST)
    date_str = now_jst.strftime("%Yå¹´%mæœˆ%dæ—¥")
    day_names = ["æœˆ", "ç«", "æ°´", "æœ¨", "é‡‘", "åœŸ", "æ—¥"]
    day_str = day_names[now_jst.weekday()]
    time_str = now_jst.strftime("%-H:%M")
    hour = now_jst.hour

    if hour < 11:
        greeting = "ãŠã¯ã‚ˆã†ã€Matsuco\U0001F44B\U0001F3FB"
    elif hour < 17:
        greeting = "ã“ã‚“ã«ã¡ã¯ã€Matsuco\U0001F44B\U0001F3FB"
    else:
        greeting = "ã“ã‚“ã°ã‚“ã¯ã€Matsuco\U0001F44B\U0001F3FB"

    sekki, kou_name, kou_reading, seasonal_desc = get_seasonal_message()
    
    # ãƒ‹ãƒ¥ãƒ¼ã‚¹é …ç›®ã®ç”Ÿæˆ
    items_html = ""
    source_counts = {}
    en_count = 0
    for item in all_items:
        source = item.get("source", "ä¸æ˜")
        source_counts[source] = source_counts.get(source, 0) + 1
        if item.get("is_translated"):
            en_count += 1
        
        items_html += f"""
        <div class="item" data-source="{source}">
            <div class="item-meta">
                <span class="source-tag">{source}</span>
                <span class="time">{item['time_ago']}</span>
            </div>
            <a href="{item['link']}" class="item-title" target="_blank">{item['title']}</a>
            <div class="item-summary">{item['summary']}</div>
            <a href="{item['link']}" class="read-more" target="_blank">ã¤ã¥ãã‚’èª­ã‚€ â†’</a>
        </div>
        """

    # ãƒ•ã‚£ãƒ«ã‚¿ãƒœã‚¿ãƒ³ã®ç”Ÿæˆ
    filter_buttons = '<div class="filters" id="filters">'
    filter_buttons += '<button class="filter-btn active" data-filter="all">ãœã‚“ã¶</button>'
    for source, count in sorted(source_counts.items(), key=lambda x: x[1], reverse=True):
        filter_buttons += f'<button class="filter-btn" data-filter="{source}">{source} <small>{count}</small></button>'
    filter_buttons += '</div>'

    # HTMLå…¨ä½“ã®çµ„ã¿ç«‹ã¦
    html_content = f"""
    <!DOCTYPE html>
    <html lang="ja">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>ã‘ã•ã®æ‰‹å¸– - {date_str}</title>
        <style>
            @import url('https://fonts.googleapis.com/css2?family=Noto+Serif+JP:wght@300;400;500;600;700&family=Zen+Maru+Gothic:wght@400;500;700&display=swap');
            * {{ margin: 0; padding: 0; box-sizing: border-box; }}
            body {{ font-family: "Zen Maru Gothic", "Noto Serif JP", serif; background: #FFFFFF; color: #3A3A3A; line-height: 1.8; letter-spacing: 0.03em; }}
            .container {{ max-width: 640px; margin: 0 auto; padding: 52px 28px 80px; }}
            .refresh-container {{ text-align: right; margin-bottom: 24px; }}
            .refresh-btn {{ padding: 6px 14px; border: 1px solid #ECE6D8; background: #FAF9F6; color: #A08060; border-radius: 20px; font-size: 11px; cursor: pointer; transition: all 0.3s ease; }}
            .refresh-btn:hover {{ background: #F0EDE5; }}
            .header {{ margin-bottom: 48px; border-bottom: 1px solid #F5F2EB; padding-bottom: 24px; }}
            .greeting {{ font-size: 24px; font-weight: 500; color: #5C5446; margin-bottom: 8px; }}
            .date {{ font-size: 13px; color: #9A9284; }}
            .season-card {{ background: #FAF9F6; border-radius: 16px; padding: 32px; margin-bottom: 48px; }}
            .season-sekki {{ font-size: 13px; color: #A08060; margin-bottom: 8px; font-weight: 500; }}
            .season-kou {{ font-size: 22px; color: #5C5446; margin-bottom: 8px; font-weight: 600; }}
            .season-reading {{ font-size: 12px; color: #B0A898; margin-bottom: 16px; }}
            .season-desc {{ font-size: 15px; color: #7C7466; line-height: 1.8; }}
            .filters {{ margin-bottom: 32px; display: flex; flex-wrap: wrap; gap: 8px; }}
            .filter-btn {{ padding: 6px 16px; border-radius: 20px; border: none; background: #F0F0F0; font-size: 12px; cursor: pointer; transition: 0.2s; }}
            .filter-btn.active {{ background: #4A4A4A; color: white; }}
            .item {{ margin-bottom: 40px; }}
            .item-meta {{ margin-bottom: 8px; font-size: 11px; }}
            .source-tag {{ background: #E0E0E0; padding: 2px 8px; border-radius: 4px; margin-right: 8px; }}
            .item-title {{ display: block; font-size: 18px; font-weight: 600; color: #3A3A3A; text-decoration: none; margin-bottom: 8px; line-height: 1.4; }}
            .item-summary {{ font-size: 14px; color: #666; margin-bottom: 8px; }}
            .read-more {{ font-size: 12px; color: #A0A0A0; text-decoration: none; }}
            .footer {{ margin-top: 80px; text-align: center; color: #B0A898; font-size: 12px; }}
        </style>
    </head>
    <body>
        <div class="container">
            <div class="refresh-container">
                <button class="refresh-btn" onclick="triggerRefresh()">æ‰‹å¸–ã‚’æœ€æ–°ã«æ›´æ–°ã™ã‚‹</button>
            </div>
            
            <div class="header">
                <div class="greeting">{greeting}</div>
                <div class="date">{date_str} ({day_str})  {time_str} å–å¾—</div>
            </div>
            
            <div class="season-card">
                <div class="season-sekki">{sekki}</div>
                <div class="season-kou">{kou_name}</div>
                <div class="season-reading">{kou_reading}</div>
                <div class="season-desc">{seasonal_desc}</div>
            </div>

            <div class="stats" style="font-size: 12px; color: #B0A898; margin-bottom: 24px;">
                {len(all_items)}ä»¶ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹
            </div>

            {filter_buttons}
            <div id="items-container">
                {items_html}
            </div>

            <div class="footer">
                <p>ãƒ» ãƒ» ãƒ»</p>
                <p>ã‘ã•ã®æ‰‹å¸– ï¼ é™ã‹ã«ã‚ã¤ã‚ã¦ã„ã¾ã™</p>
            </div>
        </div>

        <script>
        function triggerRefresh() {{
            const hookUrl = "https://api.netlify.com/build_hooks/698fddd90daa0f765f996b27";
            if (confirm("æœ€æ–°ã®æƒ…å ±ã‚’å–å¾—ã—ã«ã„ãã¾ã™ã€‚å®Œäº†ã¾ã§1ã€œ2åˆ†ã‹ã‹ã‚Šã¾ã™ãŒã€ã‚ˆã‚ã—ã„ã§ã™ã‹ï¼Ÿ")) {{
                fetch(hookUrl, {{ method: 'POST' }})
                    .then(() => alert("è·äººãŒä½œæ¥­ã‚’é–‹å§‹ã—ã¾ã—ãŸï¼å°‘ã—å¾…ã£ã¦ã‹ã‚‰å†èª­ã¿è¾¼ã¿ã—ã¦ãã ã•ã„ã€‚"))
                    .catch(() => alert("ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"));
            }}
        }}

        // ãƒ•ã‚£ãƒ«ã‚¿æ©Ÿèƒ½
        document.querySelectorAll('.filter-btn').forEach(btn => {{
            btn.addEventListener('click', () => {{
                const filter = btn.dataset.filter;
                document.querySelectorAll('.filter-btn').forEach(b => b.classList.remove('active'));
                btn.classList.add('active');
                document.querySelectorAll('.item').forEach(item => {{
                    item.style.display = (filter === 'all' || item.dataset.source === filter) ? 'block' : 'none';
                }});
            }});
        }});
        </script>
    </body>
    </html>
    """

    with open(output_path, "w", encoding="utf-8") as f:
        f.write(html_content)

def fetch_all_feeds():
    """ç”»åƒä»˜ãã§å…¨ã‚½ãƒ¼ã‚¹ã‹ã‚‰ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—ã™ã‚‹å®Œå…¨ç‰ˆ"""
    import feedparser
    from bs4 import BeautifulSoup
    from datetime import datetime, timezone
    
    # Matsucoã•ã‚“å°‚ç”¨ã®ã‚½ãƒ¼ã‚¹ä¸€è¦§
    RSS_URLS = {
        "WIRED JAPAN": "https://wired.jp/rss/rssf/",
        "Every": "https://every.to/feed",
        "Hard Fork": "https://feeds.simplecast.com/K_9_S6f_",
        "Kevin Kelly": "https://kk.org/the-technium/feed/",
        "Moltbook": "https://moltbook.xyz/feed",
        "è½åˆé™½ä¸€": "https://note.com/ochyai/rss",
        "Anthropic": "https://www.anthropic.com/index.xml", # ãƒ€ãƒªã‚ªãƒ»ã‚¢ãƒ¢ãƒ‡ã‚¤
        "Ted Chiang": "https://muckrack.com/ted-chiang/articles.rss" # ãƒ†ãƒƒãƒ‰ãƒ»ãƒãƒ£ãƒ³
    }
    
    all_items = []
    for name, url in RSS_URLS.items():
        try:
            feed = feedparser.parse(url)
            for entry in feed.entries[:5]:
                # ç”»åƒã®æŠ½å‡º
                img_url = ""
                # 1. RSSã®ã‚¿ã‚°(media:content)ã‹ã‚‰æ¢ã™
                if 'media_content' in entry:
                    img_url = entry.media_content[0]['url']
                # 2. æœ¬æ–‡(summaryã‚„content)ã®ä¸­ã®<img>ã‚¿ã‚°ã‹ã‚‰æ¢ã™
                if not img_url:
                    soup = BeautifulSoup(entry.get("summary", "") + entry.get("description", ""), 'html.parser')
                    img = soup.find('img')
                    if img: img_url = img['src']

                all_items.append({
                    "title": entry.title,
                    "link": entry.link,
                    "summary": entry.get("summary", "")[:120] + "...",
                    "date": datetime(*entry.published_parsed[:6], tzinfo=timezone.utc) if hasattr(entry, 'published_parsed') else None,
                    "source": name,
                    "image": img_url,
                    "time_ago": "æœ€è¿‘"
                })
        except:
            continue
    return all_items

def generate_html(all_items, output_path):
    # (ä¸­ç•¥: è¨ˆç®—éƒ¨åˆ†ã¯åŒã˜ã§ã™)
    
    # ãƒ‹ãƒ¥ãƒ¼ã‚¹é …ç›®ã®ç”Ÿæˆï¼ˆç”»åƒã‚ã‚ŠVerï¼‰
    items_html = ""
    for item in all_items:
        img_tag = f'<img src="{item["image"]}" class="item-img">' if item["image"] else ""
        items_html += f"""
        <div class="item" data-source="{item['source']}">
            {img_tag}
            <div class="item-meta">
                <span class="source-tag tag-{item['source'].replace(' ', '-')}">{item['source']}</span>
                <span class="time">{item['time_ago']}</span>
            </div>
            <a href="{item['link']}" class="item-title" target="_blank">{item['title']}</a>
            <div class="item-summary">{item['summary']}</div>
        </div>
        """

    # --- ãƒ‡ã‚¶ã‚¤ãƒ³ã®å¾©æ´»ï¼ˆè‰²åˆ†ã‘CSSï¼‰ ---
    html_content = f"""
    <!DOCTYPE html>
    <html lang="ja">
    <head>
        <style>
            /* ã‚½ãƒ¼ã‚¹ã”ã¨ã®è‰²åˆ†ã‘ */
            .tag-WIRED-JAPAN {{ background: #E0F2F1; color: #00796B; }}
            .tag-è½åˆé™½ä¸€ {{ background: #FCE4EC; color: #C2185B; }}
            .tag-Hard-Fork {{ background: #FFF3E0; color: #E65100; }}
            .tag-Every {{ background: #E3F2FD; color: #1976D2; }}
            .tag-Moltbook {{ background: #F3E5F5; color: #7B1FA2; }}
            .tag-Anthropic {{ background: #EFEBE9; color: #5D4037; }}
            
            /* ç”»åƒã®ã‚¹ã‚¿ã‚¤ãƒ« */
            .item-img {{ width: 100%; height: 200px; object-fit: cover; border-radius: 12px; margin-bottom: 16px; }}
            .item {{ margin-bottom: 52px; border-bottom: 1px solid #F5F2EB; padding-bottom: 32px; }}
            /* (ä»–ã®æ—¢å­˜ã‚¹ã‚¿ã‚¤ãƒ«ã¯ãã®ã¾ã¾ç¶­æŒ) */
        </style>
        ...
    </head>
    ...
    </html>
    """
    # (ä»¥ä¸‹ã€ä¿å­˜å‡¦ç†ã¨triggerRefreshã¯ä»¥å‰ã¨åŒã˜)
